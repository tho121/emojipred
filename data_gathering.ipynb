{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emoji Prediction by Tony Ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "import emoji\n",
    "import data_process\n",
    "import sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter API account keys go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "\n",
    "def twitter_Access():\n",
    "\n",
    "    client = tweepy.Client(bearer_token='')\n",
    "\n",
    "    return client\n",
    "\n",
    "extract = twitter_Access()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build queries for tweets with the top 9 emojis (recycle emoji times out too early, not enough tweets, so it is omitted).\n",
    "Filter out non-English tweets, tweets with media, and retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ðŸ˜‚) lang:en -is:retweet -has:media\n"
     ]
    }
   ],
   "source": [
    "emoji_list = ['joy',\n",
    "            'heart',\n",
    "            'sob',\n",
    "            'heart_eyes',\n",
    "            #'recycle',\n",
    "            'hearts',\n",
    "            'blush',\n",
    "            'two_hearts',\n",
    "            'kissing_heart',\n",
    "            'pensive',\n",
    "            ]\n",
    "\n",
    "emoji_list_icons = []\n",
    "\n",
    "for emj in emoji_list:\n",
    "    emoji_list_icons.append(emoji.emojize(\":\" + emj + \":\",use_aliases=True))\n",
    "\n",
    "queries = []\n",
    "\n",
    "for emj in emoji_list_icons:\n",
    "    queries.append(\"(\" + emj + \") lang:en -is:retweet -has:media\")\n",
    "\n",
    "print(queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make requests to twitter, wait for 16 minutes of rate limitations imposed, then repeat for the next emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occured, likely over the limit\n",
      "Exception occured, likely over the limit\n",
      "Exception occured, likely over the limit\n",
      "Exception occured, likely over the limit\n",
      "Exception occured, likely over the limit\n",
      "Exception occured, likely over the limit\n",
      "Exception occured, likely over the limit\n",
      "Exception occured, likely over the limit\n",
      "Exception occured, likely over the limit\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for i in range(len(emoji_list)):\n",
    "    \n",
    "    filename = \"data/\" + emoji_list[i] + \"_no_media.txt\"\n",
    "    query_string = queries[i]\n",
    "\n",
    "    with open(filename, 'a+') as f:\n",
    "\n",
    "        nxt_tkn = None\n",
    "        for i in range(1000):\n",
    "            try:\n",
    "                tweet_data = extract.search_recent_tweets(query=query_string, max_results=100, tweet_fields=['lang'], next_token=nxt_tkn)\n",
    "                nxt_tkn = tweet_data.meta.get('next_token')\n",
    "                data_process.continuous_tweet_processing(tweet_data, f) #replacing usernames and links with custom tokens\n",
    "            except:\n",
    "                print(\"Exception occured, likely over the limit\")\n",
    "                time.sleep(60 * 16)\n",
    "                break\n",
    "\n",
    "            if nxt_tkn == None:\n",
    "                print(\"No next_token returned\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are appending to an existing file, we have to remove duplicates since queries may overlap from the last time we made requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133235\n",
      "116071\n",
      "131508\n",
      "118838\n",
      "119832\n",
      "112968\n",
      "121643\n",
      "120123\n",
      "129393\n"
     ]
    }
   ],
   "source": [
    "#get only unique lines\n",
    "for emj in emoji_list:\n",
    "\n",
    "    filename = \"data/\" + emj + \"_no_media.txt\"\n",
    "    lines = []\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(line)\n",
    "\n",
    "    lines = list(set(lines))\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "    print(len(lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process raw tweet by splitting the tweet into text segments, and identifying the correct emoji as the label. Save into a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import tweet2csv\n",
    "\n",
    "for i, emj in enumerate(emoji_list):\n",
    "    filename = \"data/\" + emj\n",
    "\n",
    "    with open(filename + \"_no_media.txt\", 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        with open(filename + \"_no_media.csv\", 'w') as f_csv:\n",
    "            f_csv.write(\"emoji,text\\n\")\n",
    "\n",
    "            for line in lines:\n",
    "                csv_lines = tweet2csv(line, emoji_list_icons[i])\n",
    "\n",
    "                for csv_line in csv_lines:\n",
    "                    if emoji.is_emoji(csv_line[0]): #check against weird characters\n",
    "                        f_csv.write(csv_line)\n",
    "                        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
